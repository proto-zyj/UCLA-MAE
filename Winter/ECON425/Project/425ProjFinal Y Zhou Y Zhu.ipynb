{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn import svm, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>...</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "      <th>hardtop</th>\n",
       "      <th>hatchback</th>\n",
       "      <th>sedan</th>\n",
       "      <th>wagon</th>\n",
       "      <th>fwd</th>\n",
       "      <th>rwd</th>\n",
       "      <th>ohc</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.273171</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.180488</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>0.354419</td>\n",
       "      <td>0.491780</td>\n",
       "      <td>0.467317</td>\n",
       "      <td>0.493740</td>\n",
       "      <td>0.414106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388190</td>\n",
       "      <td>0.202540</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.370732</td>\n",
       "      <td>0.858537</td>\n",
       "      <td>0.078049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.478470</td>\n",
       "      <td>0.297446</td>\n",
       "      <td>0.385535</td>\n",
       "      <td>0.497483</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.175562</td>\n",
       "      <td>0.184139</td>\n",
       "      <td>0.178767</td>\n",
       "      <td>0.203627</td>\n",
       "      <td>0.201971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181222</td>\n",
       "      <td>0.198323</td>\n",
       "      <td>0.194127</td>\n",
       "      <td>0.475361</td>\n",
       "      <td>0.500215</td>\n",
       "      <td>0.328031</td>\n",
       "      <td>0.493865</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>0.349352</td>\n",
       "      <td>0.268905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230321</td>\n",
       "      <td>0.376119</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.254849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.066283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303207</td>\n",
       "      <td>0.479104</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.359193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.128519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460641</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.561288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.282632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        symboling    fueltype  aspiration  doornumber  enginelocation  \\\n",
       "count  205.000000  205.000000  205.000000  205.000000      205.000000   \n",
       "mean     0.273171    0.902439    0.180488    0.560976        0.985366   \n",
       "std      0.478470    0.297446    0.385535    0.497483        0.120377   \n",
       "min     -1.000000    0.000000    0.000000    0.000000        0.000000   \n",
       "25%      0.000000    1.000000    0.000000    0.000000        1.000000   \n",
       "50%      0.000000    1.000000    0.000000    1.000000        1.000000   \n",
       "75%      1.000000    1.000000    0.000000    1.000000        1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000        1.000000   \n",
       "\n",
       "        wheelbase   carlength    carwidth   carheight  curbweight  ...  \\\n",
       "count  205.000000  205.000000  205.000000  205.000000  205.000000  ...   \n",
       "mean     0.354419    0.491780    0.467317    0.493740    0.414106  ...   \n",
       "std      0.175562    0.184139    0.178767    0.203627    0.201971  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.230321    0.376119    0.316667    0.350000    0.254849  ...   \n",
       "50%      0.303207    0.479104    0.433333    0.525000    0.359193  ...   \n",
       "75%      0.460641    0.626866    0.550000    0.641667    0.561288  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "       highwaympg       price     hardtop   hatchback       sedan       wagon  \\\n",
       "count  205.000000  205.000000  205.000000  205.000000  205.000000  205.000000   \n",
       "mean     0.388190    0.202540    0.039024    0.341463    0.468293    0.121951   \n",
       "std      0.181222    0.198323    0.194127    0.475361    0.500215    0.328031   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.236842    0.066283    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.368421    0.128519    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.473684    0.282632    0.000000    1.000000    1.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "              fwd         rwd         ohc       other  \n",
       "count  205.000000  205.000000  205.000000  205.000000  \n",
       "mean     0.585366    0.370732    0.858537    0.078049  \n",
       "std      0.493865    0.484183    0.349352    0.268905  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000    0.000000    1.000000    0.000000  \n",
       "75%      1.000000    1.000000    1.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading\n",
    "path = 'D:\\\\Lab\\\\RProjects\\\\ECON432\\\\425 data\\\\cleandata.csv'\n",
    "data = pd.read_csv('cleandata.csv')\n",
    "\n",
    "# Redefine symboling to three categories\n",
    "def rangesymbol(newrange=[-1, 0, 1]):\n",
    "    for i in range(data.shape[0]):\n",
    "        if data['symboling'][i] <= -2:\n",
    "            data['symboling'][i] = newrange[0]\n",
    "        elif 2 > data['symboling'][i] > -2:\n",
    "            data['symboling'][i] = newrange[1]\n",
    "        elif data['symboling'][i] >= 2:\n",
    "            data['symboling'][i] = newrange[2]\n",
    "\n",
    "\n",
    "rangesymbol()\n",
    "ind = [\"wheelbase\",'carlength','carheight','carwidth','curbweight','enginesize','boreratio',\n",
    "                 'stroke','compressionratio','horsepower','peakrpm','citympg','highwaympg','price']\n",
    "data.loc[:, ind] = (data.loc[:, ind] - data.loc[:, ind].min())/(data.loc[:, ind].max() - data.loc[:, ind].min())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 2:data.shape[1]],\n",
    "                                                    data['symboling'], test_size=0.33, random_state=317)\n",
    "\n",
    "\n",
    "def repaccuracy(mod):\n",
    "    print('Training score is:', mod.score(X_train, y_train), '\\n',\n",
    "      'Testing score is:', mod.score(X_test, y_test), '\\n')\n",
    "    \n",
    "def confusionmatrix(predY, trueY):\n",
    "    examp = np.hstack((predY, trueY))\n",
    "    catt = list(set(trueY.iloc[:, 0]))\n",
    "    catp = list(set(predY.iloc[:, 0]))\n",
    "    catt.sort()\n",
    "    catp.sort()\n",
    "    # Just to make sure we have all categories:\n",
    "    if len(catt) >= len(catp):\n",
    "        catp = catt\n",
    "    else:\n",
    "        catt = catp\n",
    "    confmat = np.zeros((len(catt), len(catp)))\n",
    "    for i in range(len(catp)):\n",
    "        for j in range(len(catt)):\n",
    "            temp = examp == [catp[i], catt[j]]\n",
    "            temp = temp.sum(axis=1)\n",
    "            confmat[i, j] = sum(temp == 2)\n",
    "    # In the confusion matrix, rows suggest predicted, columns suggest ground truth\n",
    "    confmat = pd.DataFrame(confmat, index = catp, columns=catt)\n",
    "    accuracy = sum([confmat.iat[i, i] for i in range(confmat.shape[0])])/len(examp)\n",
    "    print('Accuracy is {}.'.format(accuracy))\n",
    "    res = []\n",
    "    res.append(accuracy)\n",
    "    for i in range(len(catp)):\n",
    "        print('Precision for yhat={} is {}.'.\n",
    "              format(confmat.columns[i], confmat.iat[i, i]/sum([confmat.iat[j, i] for j in range(len(catt))])))\n",
    "        res.append(confmat.iat[i, i]/sum([confmat.iat[j, i] for j in range(len(catt))]))\n",
    "    for i in range(len(catt)):\n",
    "        print('Recall for y={} is {}.'.\n",
    "              format(confmat.columns[i], confmat.iat[i, i]/sum([confmat.iat[i, j] for j in range(len(catp))])))\n",
    "        res.append(confmat.iat[i, i]/sum([confmat.iat[i, j] for j in range(len(catp))]))\n",
    "    print(confmat, '\\n')\n",
    "    print('Result recorded', '\\n')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.948905109489051 \n",
      " Testing score is: 0.6764705882352942 \n",
      "\n",
      "Accuracy is 0.6764705882352942.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8409090909090909.\n",
      "Precision for yhat=1 is 0.34782608695652173.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.7115384615384616.\n",
      "Recall for y=1 is 0.6153846153846154.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  37.0  15.0\n",
      " 1  0.0   5.0   8.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Res = []\n",
    "#M1\n",
    "# OVR,None penalty,newton-cg\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"none\",solver = \"newton-cg\", max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.948905109489051 \n",
      " Testing score is: 0.6617647058823529 \n",
      "\n",
      "Accuracy is 0.6617647058823529.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8181818181818182.\n",
      "Precision for yhat=1 is 0.34782608695652173.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.7058823529411765.\n",
      "Recall for y=1 is 0.5714285714285714.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  36.0  15.0\n",
      " 1  0.0   6.0   8.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M2\n",
    "# OVR,None penalty,lbfgs\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"none\",solver = \"lbfgs\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.948905109489051 \n",
      " Testing score is: 0.7352941176470589 \n",
      "\n",
      "Accuracy is 0.7352941176470589.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.391304347826087.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.7407407407407407.\n",
      "Recall for y=1 is 0.75.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  40.0  14.0\n",
      " 1  0.0   3.0   9.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M3\n",
    "# OVR,None penalty,sag\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"none\",solver = \"sag\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9416058394160584 \n",
      " Testing score is: 0.7647058823529411 \n",
      "\n",
      "Accuracy is 0.7647058823529411.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9318181818181818.\n",
      "Precision for yhat=1 is 0.43478260869565216.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.7592592592592593.\n",
      "Recall for y=1 is 0.8333333333333334.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  41.0  13.0\n",
      " 1  0.0   2.0  10.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M4\n",
    "# OVR,None penalty,saga\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"none\",solver = \"saga\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8029197080291971 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M5\n",
    "# OVR,L1 ,liblinear\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l1\",solver = \"liblinear\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8029197080291971 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M6\n",
    "# OVR,L1 ,saga\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l1\",solver = \"saga\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8029197080291971 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M7\n",
    "# OVR,L2 ,liblinear\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l2\",solver = \"liblinear\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8029197080291971 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M8\n",
    "# OVR,L2 ,newton-cg\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l2\",solver = \"newton-cg\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8029197080291971 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M9\n",
    "# OVR,L2 ,lbfgs\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l2\",solver = \"lbfgs\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8029197080291971 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M10\n",
    "# OVR,L2 ,sag\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l2\",solver = \"sag\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8029197080291971 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M11\n",
    "# OVR,L2 ,saga,lamda = 1\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l2\",solver = \"saga\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.7226277372262774 \n",
      " Testing score is: 0.6470588235294118 \n",
      "\n",
      "Accuracy is 0.6470588235294118.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 1.0.\n",
      "Precision for yhat=1 is 0.0.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.6470588235294118.\n",
      "Recall for y=1 is nan.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  44.0  23.0\n",
      " 1  0.0   0.0   0.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M12\n",
    "# OVR,L2 ,saga,lambda = 1000\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l2\",solver = \"saga\",C = 0.001,max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9197080291970803 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9545454545454546.\n",
      "Precision for yhat=1 is 0.43478260869565216.\n",
      "Recall for y=-1 is 1.0.\n",
      "Recall for y=0 is 0.7636363636363637.\n",
      "Recall for y=1 is 0.8333333333333334.\n",
      "     -1     0     1\n",
      "-1  1.0   0.0   0.0\n",
      " 0  0.0  42.0  13.0\n",
      " 1  0.0   2.0  10.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M13\n",
    "# OVR,L2 ,saga lambda = 0.001\n",
    "logistic = LogisticRegression(multi_class=\"ovr\",penalty = \"l2\",solver = \"saga\",C = 1000,max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9562043795620438 \n",
      " Testing score is: 0.6617647058823529 \n",
      "\n",
      "Accuracy is 0.6617647058823529.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8409090909090909.\n",
      "Precision for yhat=1 is 0.30434782608695654.\n",
      "Recall for y=-1 is 0.25.\n",
      "Recall for y=0 is 0.7115384615384616.\n",
      "Recall for y=1 is 0.5833333333333334.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   1.0\n",
      " 0  0.0  37.0  15.0\n",
      " 1  0.0   5.0   7.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M14\n",
    "# OVO,none,newton-cg\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"none\",solver = \"newton-cg\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9562043795620438 \n",
      " Testing score is: 0.6470588235294118 \n",
      "\n",
      "Accuracy is 0.6470588235294118.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8181818181818182.\n",
      "Precision for yhat=1 is 0.30434782608695654.\n",
      "Recall for y=-1 is 0.2.\n",
      "Recall for y=0 is 0.7058823529411765.\n",
      "Recall for y=1 is 0.5833333333333334.\n",
      "     -1     0     1\n",
      "-1  1.0   3.0   1.0\n",
      " 0  0.0  36.0  15.0\n",
      " 1  0.0   5.0   7.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M15\n",
    "# OVO,none,lbfgs\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"none\",solver = \"lbfgs\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9562043795620438 \n",
      " Testing score is: 0.7058823529411765 \n",
      "\n",
      "Accuracy is 0.7058823529411765.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8636363636363636.\n",
      "Precision for yhat=1 is 0.391304347826087.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.7307692307692307.\n",
      "Recall for y=1 is 0.6428571428571429.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  38.0  14.0\n",
      " 1  0.0   5.0   9.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M16\n",
    "#OVO,none,sag\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"none\",solver = \"sag\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.948905109489051 \n",
      " Testing score is: 0.7205882352941176 \n",
      "\n",
      "Accuracy is 0.7205882352941176.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8863636363636364.\n",
      "Precision for yhat=1 is 0.391304347826087.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.7358490566037735.\n",
      "Recall for y=1 is 0.6923076923076923.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  39.0  14.0\n",
      " 1  0.0   4.0   9.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M17\n",
    "# OVO,none,saga\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"none\",solver = \"saga\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8102189781021898 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M18\n",
    "# OVO,l1,saga\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"l1\",solver = \"saga\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8175182481751825 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M19\n",
    "# OVO,l2,newton-cg\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"l2\",solver = \"newton-cg\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8175182481751825 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M20\n",
    "# OVO,l2,lbfgs\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"l2\",solver = \"lbfgs\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8175182481751825 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M21\n",
    "# OVO,l2,sag\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"l2\",solver = \"sag\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8175182481751825 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M22\n",
    "# OVO,l2,saga, lamda = 1\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"l2\",solver = \"saga\",max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.7226277372262774 \n",
      " Testing score is: 0.6470588235294118 \n",
      "\n",
      "Accuracy is 0.6470588235294118.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 1.0.\n",
      "Precision for yhat=1 is 0.0.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.6470588235294118.\n",
      "Recall for y=1 is nan.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  44.0  23.0\n",
      " 1  0.0   0.0   0.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M23\n",
    "# OVO,l2,saga,lambda = 1000\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"l2\",solver = \"saga\",C =0.001,max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9562043795620438 \n",
      " Testing score is: 0.75 \n",
      "\n",
      "Accuracy is 0.75.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9318181818181818.\n",
      "Precision for yhat=1 is 0.391304347826087.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.7454545454545455.\n",
      "Recall for y=1 is 0.8181818181818182.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  41.0  14.0\n",
      " 1  0.0   2.0   9.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M24\n",
    "# OVO,l2,saga,lambda = 0.001\n",
    "logistic = LogisticRegression(multi_class=\"multinomial\",penalty = \"l2\",solver = \"saga\",C =1000,max_iter=10000)\n",
    "lr = logistic.fit(X_train,y_train)\n",
    "repaccuracy(lr)\n",
    "Res.append(confusionmatrix(DataFrame(lr.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def knn_score(n,weights,p):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n, weights = weights,p=p)\n",
    "    knn = knn.fit(X_train,y_train)\n",
    "    print(f\"train score {knn.score(X_train,y_train)} for {n}\")\n",
    "    print(f\"test score {knn.score(X_test,y_test)} for {n}\")\n",
    "    repaccuracy(knn)\n",
    "    Res.append(confusionmatrix(DataFrame(knn.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 1.0 for 1\n",
      "test score 0.8088235294117647 for 1\n",
      "Training score is: 1.0 \n",
      " Testing score is: 0.8088235294117647 \n",
      "\n",
      "Accuracy is 0.8088235294117647.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.6086956521739131.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.8163265306122449.\n",
      "Recall for y=1 is 0.875.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  40.0   9.0\n",
      " 1  0.0   2.0  14.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M25\n",
    "#n=1 uniform manhattan \n",
    "knn_score(1, \"uniform\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 1.0 for 1\n",
      "test score 0.7794117647058824 for 1\n",
      "Training score is: 1.0 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8636363636363636.\n",
      "Precision for yhat=1 is 0.6086956521739131.\n",
      "Recall for y=-1 is 0.25.\n",
      "Recall for y=0 is 0.8260869565217391.\n",
      "Recall for y=1 is 0.7777777777777778.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   1.0\n",
      " 0  0.0  38.0   8.0\n",
      " 1  0.0   4.0  14.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M26\n",
    "# n=1 uniform euclidean\n",
    "knn_score(1, \"uniform\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 1.0 for 1\n",
      "test score 0.7794117647058824 for 1\n",
      "Training score is: 1.0 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8636363636363636.\n",
      "Precision for yhat=1 is 0.6086956521739131.\n",
      "Recall for y=-1 is 0.25.\n",
      "Recall for y=0 is 0.8260869565217391.\n",
      "Recall for y=1 is 0.7777777777777778.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   1.0\n",
      " 0  0.0  38.0   8.0\n",
      " 1  0.0   4.0  14.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M27\n",
    "# n=1 uniform minkowski\n",
    "knn_score(1, \"uniform\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8467153284671532 for 5\n",
      "test score 0.7941176470588235 for 5\n",
      "Training score is: 0.8467153284671532 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9318181818181818.\n",
      "Precision for yhat=1 is 0.5652173913043478.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7884615384615384.\n",
      "Recall for y=1 is 0.8125.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  41.0  10.0\n",
      " 1  0.0   3.0  13.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M28\n",
    "# n=5 uniform manhattan \n",
    "knn_score(5, \"uniform\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.7883211678832117 for 10\n",
      "test score 0.8088235294117647 for 10\n",
      "Training score is: 0.7883211678832117 \n",
      " Testing score is: 0.8088235294117647 \n",
      "\n",
      "Accuracy is 0.8088235294117647.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.5217391304347826.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7818181818181819.\n",
      "Recall for y=1 is 0.9230769230769231.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  11.0\n",
      " 1  0.0   1.0  12.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M29\n",
    "# n=10 uniform manhattan \n",
    "knn_score(10, \"uniform\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 1.0 for 1\n",
      "test score 0.8088235294117647 for 1\n",
      "Training score is: 1.0 \n",
      " Testing score is: 0.8088235294117647 \n",
      "\n",
      "Accuracy is 0.8088235294117647.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.6086956521739131.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.8163265306122449.\n",
      "Recall for y=1 is 0.875.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  40.0   9.0\n",
      " 1  0.0   2.0  14.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M30\n",
    "# n=1 distance manhattan\n",
    "knn_score(1, \"distance\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 1.0 for 1\n",
      "test score 0.7794117647058824 for 1\n",
      "Training score is: 1.0 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8636363636363636.\n",
      "Precision for yhat=1 is 0.6086956521739131.\n",
      "Recall for y=-1 is 0.25.\n",
      "Recall for y=0 is 0.8260869565217391.\n",
      "Recall for y=1 is 0.7777777777777778.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   1.0\n",
      " 0  0.0  38.0   8.0\n",
      " 1  0.0   4.0  14.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M31\n",
    "# n=1 distance euclidean\n",
    "knn_score(1, \"distance\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 1.0 for 1\n",
      "test score 0.7794117647058824 for 1\n",
      "Training score is: 1.0 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8636363636363636.\n",
      "Precision for yhat=1 is 0.6086956521739131.\n",
      "Recall for y=-1 is 0.25.\n",
      "Recall for y=0 is 0.8260869565217391.\n",
      "Recall for y=1 is 0.7777777777777778.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   1.0\n",
      " 0  0.0  38.0   8.0\n",
      " 1  0.0   4.0  14.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M32\n",
    "# n=1 distance minkowski\n",
    "knn_score(1, \"distance\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 1.0 for 5\n",
      "test score 0.8676470588235294 for 5\n",
      "Training score is: 1.0 \n",
      " Testing score is: 0.8676470588235294 \n",
      "\n",
      "Accuracy is 0.8676470588235294.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.6521739130434783.\n",
      "Recall for y=-1 is 1.0.\n",
      "Recall for y=0 is 0.8431372549019608.\n",
      "Recall for y=1 is 0.9375.\n",
      "     -1     0     1\n",
      "-1  1.0   0.0   0.0\n",
      " 0  0.0  43.0   8.0\n",
      " 1  0.0   1.0  15.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M33\n",
    "# n=5 distance manhattan\n",
    "knn_score(5, \"distance\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 1.0 for 10\n",
      "test score 0.8529411764705882 for 10\n",
      "Training score is: 1.0 \n",
      " Testing score is: 0.8529411764705882 \n",
      "\n",
      "Accuracy is 0.8529411764705882.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9545454545454546.\n",
      "Precision for yhat=1 is 0.6521739130434783.\n",
      "Recall for y=-1 is 1.0.\n",
      "Recall for y=0 is 0.84.\n",
      "Recall for y=1 is 0.8823529411764706.\n",
      "     -1     0     1\n",
      "-1  1.0   0.0   0.0\n",
      " 0  0.0  42.0   8.0\n",
      " 1  0.0   2.0  15.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M34\n",
    "# n=10 distance manhattan\n",
    "knn_score(10, \"distance\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9927007299270073 \n",
      " Testing score is: 0.8235294117647058 \n",
      "\n",
      "Accuracy is 0.8235294117647058.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9545454545454546.\n",
      "Precision for yhat=1 is 0.5652173913043478.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.8076923076923077.\n",
      "Recall for y=1 is 0.9285714285714286.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  42.0  10.0\n",
      " 1  0.0   1.0  13.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we have 28 features, try 30 perceptrons\n",
    "# M35\n",
    "# relu adam constant 1 hidden layer\n",
    "NN = MLPClassifier(max_iter = 2000,hidden_layer_sizes=(30,))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8235294117647058 \n",
      "\n",
      "Accuracy is 0.8235294117647058.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9545454545454546.\n",
      "Precision for yhat=1 is 0.5652173913043478.\n",
      "Recall for y=-1 is 1.0.\n",
      "Recall for y=0 is 0.8076923076923077.\n",
      "Recall for y=1 is 0.8666666666666667.\n",
      "     -1     0     1\n",
      "-1  1.0   0.0   0.0\n",
      " 0  0.0  42.0  10.0\n",
      " 1  0.0   2.0  13.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M36\n",
    "# relu adam constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 2000,hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8088235294117647 \n",
      "\n",
      "Accuracy is 0.8088235294117647.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9318181818181818.\n",
      "Precision for yhat=1 is 0.5652173913043478.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.803921568627451.\n",
      "Recall for y=1 is 0.8666666666666667.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  41.0  10.0\n",
      " 1  0.0   2.0  13.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M37\n",
    "# relu adam constant 3 hidden layer\n",
    "NN = MLPClassifier(max_iter = 2000,hidden_layer_sizes=(30,30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8382352941176471 \n",
      "\n",
      "Accuracy is 0.8382352941176471.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9545454545454546.\n",
      "Precision for yhat=1 is 0.6086956521739131.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.84.\n",
      "Recall for y=1 is 0.9333333333333333.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   1.0\n",
      " 0  0.0  42.0   8.0\n",
      " 1  0.0   1.0  14.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M38\n",
    "# relu lbfgs constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 2000,solver = 'lbfgs',hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.7956204379562044 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.43478260869565216.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7543859649122807.\n",
      "Recall for y=1 is 0.9090909090909091.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  13.0\n",
      " 1  0.0   1.0  10.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M39\n",
    "# relu sgd constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 20000,solver = 'sgd',hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9854014598540146 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.6086956521739131.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.8.\n",
      "Recall for y=1 is 0.7777777777777778.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  40.0   9.0\n",
      " 1  0.0   4.0  14.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M40\n",
    "# logistic adam constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 20000,solver = 'adam',activation=\"logistic\",hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8382352941176471 \n",
      "\n",
      "Accuracy is 0.8382352941176471.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9318181818181818.\n",
      "Precision for yhat=1 is 0.6521739130434783.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.8367346938775511.\n",
      "Recall for y=1 is 0.9375.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  41.0   8.0\n",
      " 1  0.0   1.0  15.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M41\n",
    "# logistic lbfgs constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 20000,solver = 'lbfgs',activation=\"logistic\",hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.7226277372262774 \n",
      " Testing score is: 0.6470588235294118 \n",
      "\n",
      "Accuracy is 0.6470588235294118.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 1.0.\n",
      "Precision for yhat=1 is 0.0.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.6470588235294118.\n",
      "Recall for y=1 is nan.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  44.0  23.0\n",
      " 1  0.0   0.0   0.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M42\n",
    "# logistic sgd constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 20000,solver = 'sgd',activation=\"logistic\",hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8235294117647058 \n",
      "\n",
      "Accuracy is 0.8235294117647058.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9545454545454546.\n",
      "Precision for yhat=1 is 0.5652173913043478.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.8235294117647058.\n",
      "Recall for y=1 is 0.9285714285714286.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   1.0\n",
      " 0  0.0  42.0   9.0\n",
      " 1  0.0   1.0  13.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M43\n",
    "# tanh adam constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 20000,solver = 'adam',activation=\"tanh\",hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8676470588235294 \n",
      "\n",
      "Accuracy is 0.8676470588235294.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9545454545454546.\n",
      "Precision for yhat=1 is 0.6956521739130435.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.8571428571428571.\n",
      "Recall for y=1 is 0.9411764705882353.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  42.0   7.0\n",
      " 1  0.0   1.0  16.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M44\n",
    "# tanh lbfgs constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 20000,solver = 'lbfgs',activation=\"tanh\",hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.7883211678832117 \n",
      " Testing score is: 0.7352941176470589 \n",
      "\n",
      "Accuracy is 0.7352941176470589.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.30434782608695654.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7166666666666667.\n",
      "Recall for y=1 is 0.875.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  16.0\n",
      " 1  0.0   1.0   7.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M45\n",
    "# tanh sgd constant 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 20000,solver = 'sgd',activation=\"tanh\",hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8235294117647058 \n",
      "\n",
      "Accuracy is 0.8235294117647058.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9545454545454546.\n",
      "Precision for yhat=1 is 0.5652173913043478.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.8076923076923077.\n",
      "Recall for y=1 is 0.9285714285714286.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  42.0  10.0\n",
      " 1  0.0   1.0  13.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M46\n",
    "# tanh lbfgs adaptive 2 hidden layer\n",
    "NN = MLPClassifier(max_iter = 20000,solver = 'lbfgs',learning_rate='adaptive',activation=\"tanh\",hidden_layer_sizes=(30,30))\n",
    "NN = NN.fit(X_train,y_train)\n",
    "repaccuracy(NN)\n",
    "Res.append(confusionmatrix(DataFrame(NN.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8248175182481752 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is 0.0.\n",
      "Recall for y=0 is 0.7818181818181819.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   1.0\n",
      " 0  1.0  43.0  11.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M47\n",
    "# OVO, linear\n",
    "svm1 = svm.SVC(decision_function_shape='ovo', kernel='linear', max_iter=10000\n",
    "               ).fit(X_train, y_train)\n",
    "repaccuracy(svm1)\n",
    "Res.append(confusionmatrix(DataFrame(svm1.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8540145985401459 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M48\n",
    "# OVO, LinearSVC\n",
    "svmL = svm.LinearSVC(C=1, max_iter=2000000).fit(X_train, y_train)\n",
    "repaccuracy(svmL)\n",
    "Res.append(confusionmatrix(DataFrame(svmL.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8102189781021898 \n",
      " Testing score is: 0.7941176470588235 \n",
      "\n",
      "Accuracy is 0.7941176470588235.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.4782608695652174.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7678571428571429.\n",
      "Recall for y=1 is 0.9166666666666666.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  12.0\n",
      " 1  0.0   1.0  11.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M49\n",
    "# OVO, LinearSVC, soft margin 0.2\n",
    "svmL2 = svm.LinearSVC(C=0.2, max_iter=2000000).fit(X_train, y_train)\n",
    "repaccuracy(svmL2)\n",
    "Res.append(confusionmatrix(DataFrame(svmL2.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8248175182481752 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.43478260869565216.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7543859649122807.\n",
      "Recall for y=1 is 0.9090909090909091.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  13.0\n",
      " 1  0.0   1.0  10.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M50\n",
    "# OVO, polynomial, degree=2, coef0=5\n",
    "svm2 = svm.SVC(C=1, decision_function_shape='ovo',\n",
    "               kernel='poly', max_iter=10000000,\n",
    "               degree=2, coef0=5, gamma='auto').fit(X_train, y_train)\n",
    "repaccuracy(svm2)\n",
    "Res.append(confusionmatrix(DataFrame(svm2.predict(X_test)), DataFrame(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8248175182481752 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.43478260869565216.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7543859649122807.\n",
      "Recall for y=1 is 0.9090909090909091.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  13.0\n",
      " 1  0.0   1.0  10.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M51\n",
    "# OVO, polynomial, degree=3, coef0=5\n",
    "svm2 = svm.SVC(C=1, decision_function_shape='ovo',\n",
    "               kernel='poly', max_iter=10000000,\n",
    "               degree=2, coef0=5, gamma='auto').fit(X_train, y_train)\n",
    "repaccuracy(svm2)\n",
    "Res.append(confusionmatrix(DataFrame(svm2.predict(X_test)), DataFrame(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8248175182481752 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.43478260869565216.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7543859649122807.\n",
      "Recall for y=1 is 0.9090909090909091.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  13.0\n",
      " 1  0.0   1.0  10.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M52\n",
    "# OVO, polynomial, degree=5, coef0=5\n",
    "svm2 = svm.SVC(C=1, decision_function_shape='ovo',\n",
    "               kernel='poly', max_iter=10000000,\n",
    "               degree=2, coef0=5, gamma='auto').fit(X_train, y_train)\n",
    "repaccuracy(svm2)\n",
    "Res.append(confusionmatrix(DataFrame(svm2.predict(X_test)), DataFrame(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8248175182481752 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.43478260869565216.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7543859649122807.\n",
      "Recall for y=1 is 0.9090909090909091.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  13.0\n",
      " 1  0.0   1.0  10.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M53\n",
    "# OVO, polynomial, degree=2, coef0=1\n",
    "svm2 = svm.SVC(C=1, decision_function_shape='ovo',\n",
    "               kernel='poly', max_iter=10000000,\n",
    "               degree=2, coef0=5, gamma='auto').fit(X_train, y_train)\n",
    "repaccuracy(svm2)\n",
    "Res.append(confusionmatrix(DataFrame(svm2.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9124087591240876 \n",
      " Testing score is: 0.75 \n",
      "\n",
      "Accuracy is 0.75.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 1.0.\n",
      "Precision for yhat=1 is 0.30434782608695654.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7213114754098361.\n",
      "Recall for y=1 is 1.0.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  44.0  16.0\n",
      " 1  0.0   0.0   7.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M54\n",
    "# OVO, exponential, gamma=3\n",
    "svm3 = svm.SVC(decision_function_shape='ovo',\n",
    "               kernel='rbf', gamma=3, max_iter=100000).fit(X_train, y_train)\n",
    "repaccuracy(svm3)\n",
    "Res.append(confusionmatrix(DataFrame(svm3.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.8613138686131386 \n",
      " Testing score is: 0.7794117647058824 \n",
      "\n",
      "Accuracy is 0.7794117647058824.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.43478260869565216.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.7543859649122807.\n",
      "Recall for y=1 is 0.9090909090909091.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  13.0\n",
      " 1  0.0   1.0  10.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M55\n",
    "# OVO, exponential, gamma=0.46\n",
    "svm32 = svm.SVC(decision_function_shape='ovo',\n",
    "               kernel='rbf', gamma=0.46, max_iter=100000).fit(X_train, y_train)\n",
    "repaccuracy(svm32)\n",
    "Res.append(confusionmatrix(DataFrame(svm32.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.9854014598540146 \n",
      " Testing score is: 0.7058823529411765 \n",
      "\n",
      "Accuracy is 0.7058823529411765.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9772727272727273.\n",
      "Precision for yhat=1 is 0.21739130434782608.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.6935483870967742.\n",
      "Recall for y=1 is 0.8333333333333334.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  43.0  18.0\n",
      " 1  0.0   1.0   5.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M56\n",
    "# OVO, exponential, gamma=15\n",
    "svm33 = svm.SVC(decision_function_shape='ovo',\n",
    "               kernel='rbf', gamma=15, max_iter=100000).fit(X_train, y_train)\n",
    "repaccuracy(svm33)\n",
    "Res.append(confusionmatrix(DataFrame(svm33.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 0.7226277372262774 \n",
      " Testing score is: 0.6470588235294118 \n",
      "\n",
      "Accuracy is 0.6470588235294118.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 1.0.\n",
      "Precision for yhat=1 is 0.0.\n",
      "Recall for y=-1 is nan.\n",
      "Recall for y=0 is 0.6470588235294118.\n",
      "Recall for y=1 is nan.\n",
      "     -1     0     1\n",
      "-1  0.0   0.0   0.0\n",
      " 0  1.0  44.0  23.0\n",
      " 1  0.0   0.0   0.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M57\n",
    "# OVO, sigmoid, gamma=auto\n",
    "svm4 = svm.SVC(decision_function_shape='ovo',\n",
    "               kernel='sigmoid', gamma='auto').fit(X_train, y_train)\n",
    "repaccuracy(svm4)\n",
    "Res.append(confusionmatrix(DataFrame(svm4.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md \n"
    }
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8382352941176471 \n",
      "\n",
      "Accuracy is 0.8382352941176471.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.6956521739130435.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.851063829787234.\n",
      "Recall for y=1 is 0.8421052631578947.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  40.0   7.0\n",
      " 1  0.0   3.0  16.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M58\n",
    "# gini, max depth 15\n",
    "dtree = DTC(criterion='gini', max_depth=15, max_features=None).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8382352941176471 \n",
      "\n",
      "Accuracy is 0.8382352941176471.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.6956521739130435.\n",
      "Recall for y=-1 is 1.0.\n",
      "Recall for y=0 is 0.851063829787234.\n",
      "Recall for y=1 is 0.8.\n",
      "     -1     0     1\n",
      "-1  1.0   0.0   0.0\n",
      " 0  0.0  40.0   7.0\n",
      " 1  0.0   4.0  16.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M59\n",
    "# gini, max depth 50\n",
    "dtree = DTC(criterion='gini', max_depth=50, max_features=None).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8676470588235294 \n",
      "\n",
      "Accuracy is 0.8676470588235294.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.782608695652174.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.8888888888888888.\n",
      "Recall for y=1 is 0.9.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  40.0   5.0\n",
      " 1  0.0   2.0  18.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M60\n",
    "# gini, max depth 15ï¼Œ max feature10\n",
    "dtree = DTC(criterion='gini', max_depth=15, max_features=10).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8088235294117647 \n",
      "\n",
      "Accuracy is 0.8088235294117647.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8409090909090909.\n",
      "Precision for yhat=1 is 0.7391304347826086.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.8604651162790697.\n",
      "Recall for y=1 is 0.7727272727272727.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  37.0   6.0\n",
      " 1  0.0   5.0  17.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M61\n",
    "# entropy, max depth 15\n",
    "dtree = DTC(criterion='entropy', max_depth=15, max_features=None).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8529411764705882 \n",
      "\n",
      "Accuracy is 0.8529411764705882.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.7391304347826086.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.8695652173913043.\n",
      "Recall for y=1 is 0.8947368421052632.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  40.0   6.0\n",
      " 1  0.0   2.0  17.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M62\n",
    "# entropy, max depth 50\n",
    "dtree = DTC(criterion='entropy', max_depth=50, max_features=None).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.9117647058823529 \n",
      "\n",
      "Accuracy is 0.9117647058823529.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.9130434782608695.\n",
      "Recall for y=-1 is 0.5.\n",
      "Recall for y=0 is 0.9523809523809523.\n",
      "Recall for y=1 is 0.875.\n",
      "     -1     0     1\n",
      "-1  1.0   1.0   0.0\n",
      " 0  0.0  40.0   2.0\n",
      " 1  0.0   3.0  21.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M63\n",
    "# entropy, max depth 15, max feature 10\n",
    "dtree = DTC(criterion='entropy', max_depth=15, max_features=10).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8676470588235294 \n",
      "\n",
      "Accuracy is 0.8676470588235294.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.8863636363636364.\n",
      "Precision for yhat=1 is 0.8695652173913043.\n",
      "Recall for y=-1 is 0.0.\n",
      "Recall for y=0 is 0.9069767441860465.\n",
      "Recall for y=1 is 0.8695652173913043.\n",
      "     -1     0     1\n",
      "-1  0.0   2.0   0.0\n",
      " 0  1.0  39.0   3.0\n",
      " 1  0.0   3.0  20.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M64\n",
    "# entropy, max depth 50, max feature 10\n",
    "dtree = DTC(criterion='entropy', max_depth=50, max_features=10).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8235294117647058 \n",
      "\n",
      "Accuracy is 0.8235294117647058.\n",
      "Precision for yhat=-1 is 1.0.\n",
      "Precision for yhat=0 is 0.8636363636363636.\n",
      "Precision for yhat=1 is 0.7391304347826086.\n",
      "Recall for y=-1 is 0.3333333333333333.\n",
      "Recall for y=0 is 0.8636363636363636.\n",
      "Recall for y=1 is 0.8095238095238095.\n",
      "     -1     0     1\n",
      "-1  1.0   2.0   0.0\n",
      " 0  0.0  38.0   6.0\n",
      " 1  0.0   4.0  17.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M65\n",
    "# entropy, max depth 50, max feature 15\n",
    "dtree = DTC(criterion='entropy', max_depth=50, max_features=15).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is: 1.0 \n",
      " Testing score is: 0.8529411764705882 \n",
      "\n",
      "Accuracy is 0.8529411764705882.\n",
      "Precision for yhat=-1 is 0.0.\n",
      "Precision for yhat=0 is 0.9090909090909091.\n",
      "Precision for yhat=1 is 0.782608695652174.\n",
      "Recall for y=-1 is 0.0.\n",
      "Recall for y=0 is 0.8695652173913043.\n",
      "Recall for y=1 is 0.8571428571428571.\n",
      "     -1     0     1\n",
      "-1  0.0   1.0   0.0\n",
      " 0  1.0  40.0   5.0\n",
      " 1  0.0   3.0  18.0 \n",
      "\n",
      "Result recorded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#M66\n",
    "# entropy, max depth 50, max feature 6\n",
    "dtree = DTC(criterion='entropy', max_depth=50, max_features=6).fit(X_train, y_train)\n",
    "repaccuracy(dtree)\n",
    "Res.append(confusionmatrix(DataFrame(dtree.predict(X_test)), DataFrame(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ResDF = pd.DataFrame(Res)\n",
    "modellist = ['LR OVR,None penalty,newton-cg', 'OVR,None penalty,lbfgs', 'OVR,None penalty,sag', \n",
    "             'OVR,None penalty,saga', 'OVR,L1 ,liblinear', 'OVR,L1 ,saga', \n",
    "             'OVR,L2 ,liblinear', 'OVR,L2 ,newton-cg', 'OVR,L2 ,lbfgs', \n",
    "             'OVR,L2 ,sag', 'OVR,L2 ,saga,lambda=1', 'OVR,L2 ,saga,lambda=1000', \n",
    "             'OVR,L2 ,saga,lambda=0.001', 'OVO,none,newton-cg', \n",
    "             'OVO,none,lbfgs', 'OVO,none,sag', 'OVO,none,saga', \n",
    "             'OVO,l1,saga', 'OVO,l2,newton-cg', 'OVO,l2,lbfgs', \n",
    "             'OVO,l2,sag', 'OVO,l2,saga,lamda=1', 'OVO,L2 ,saga,lambda=1000', \n",
    "             'OVO,L2 ,saga,lambda=0.001', 'KNN,N=1,uniform,p=1', \n",
    "             'KNN,N=1,uniform,p=2', 'KNN,N=1,uniform,p=3', 'KNN,N=5,uniform,p=1', \n",
    "             'KNN,N=10,uniform,p=1', 'KNN,N=1,distance,p=1', 'KNN,N=1,distance,p=2', \n",
    "             'KNN,N=1,distance,p=3', 'KNN,N=5,distance,p=1', 'KNN,N=10,distance,p=1', \n",
    "             'MLP relu adam constant 1 hidden layer', 'relu adam constant 2 hidden layer', 'relu adam constant 3 hidden layer', \n",
    "             'relu lbfgs constant 2 hidden layer', 'relu sgd constant 2 hidden layer', 'logistic adam constant 2 hidden layer', \n",
    "             'logistic lbfgs constant 2 hidden layer', 'logistic sgd constant 2 hidden layer', 'tanh adam constant 2 hidden layer', \n",
    "             'tanh lbfgs constant 2 hidden layer', 'tanh sgd constant 2 hidden layer', 'tanh lbfgs adaptive 2 hidden layer', \n",
    "             'SVM OVO, linear', 'OVO, LinearSVC', 'OVO, LinearSVC, soft margin 0.2', \n",
    "             'OVO, polynomial, degree=2, coef0=5', 'OVO, polynomial, degree=3, coef0=5', 'OVO, polynomial, degree=5, coef0=5', \n",
    "             'OVO, polynomial, degree=2, coef0=1', 'OVO, exponential, gamma=3', 'OVO, exponential, gamma=0.46', \n",
    "             'OVO, exponential, gamma=15', 'OVO, sigmoid, gamma=auto', 'Decision Tree gini, max depth 15', \n",
    "             'gini, max depth 50', 'gini, max depth 15, max feature10', 'entropy, max depth 15', \n",
    "             'entropy, max depth 50', 'entropy, max depth 15, max feature 10', 'entropy, max depth 50, max feature 10', \n",
    "             'entropy, max depth 50, max feature 15', 'entropy, max depth 50, max feature 6']\n",
    "ResDF.index = pd.Series(modellist)\n",
    "ResDF.columns = ['Accuracy', 'Precision-1', 'Precision0', 'Precision+1', \n",
    "                 'Recall-1', 'Recall0', 'Recall+1']\n",
    "ResDF.to_csv('mdres.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}